{"ast":null,"code":"import \"core-js/modules/es.array-buffer.detached.js\";\nimport \"core-js/modules/es.array-buffer.transfer.js\";\nimport \"core-js/modules/es.array-buffer.transfer-to-fixed-length.js\";\nimport \"core-js/modules/es.typed-array.with.js\";\nimport \"core-js/modules/esnext.uint8-array.set-from-base64.js\";\nimport \"core-js/modules/esnext.uint8-array.set-from-hex.js\";\nimport \"core-js/modules/esnext.uint8-array.to-base64.js\";\nimport \"core-js/modules/esnext.uint8-array.to-hex.js\";\nimport { EndOfStreamError } from './stream/index.js';\n/**\r\n * Core tokenizer\r\n */\nexport class AbstractTokenizer {\n  /**\r\n   * Constructor\r\n   * @param options Tokenizer options\r\n   * @protected\r\n   */\n  constructor(options) {\n    this.numBuffer = new Uint8Array(8);\n    /**\r\n     * Tokenizer-stream position\r\n     */\n    this.position = 0;\n    this.onClose = options?.onClose;\n    if (options?.abortSignal) {\n      options.abortSignal.addEventListener('abort', () => {\n        this.abort();\n      });\n    }\n  }\n  /**\r\n   * Read a token from the tokenizer-stream\r\n   * @param token - The token to read\r\n   * @param position - If provided, the desired position in the tokenizer-stream\r\n   * @returns Promise with token data\r\n   */\n  async readToken(token, position = this.position) {\n    const uint8Array = new Uint8Array(token.len);\n    const len = await this.readBuffer(uint8Array, {\n      position\n    });\n    if (len < token.len) throw new EndOfStreamError();\n    return token.get(uint8Array, 0);\n  }\n  /**\r\n   * Peek a token from the tokenizer-stream.\r\n   * @param token - Token to peek from the tokenizer-stream.\r\n   * @param position - Offset where to begin reading within the file. If position is null, data will be read from the current file position.\r\n   * @returns Promise with token data\r\n   */\n  async peekToken(token, position = this.position) {\n    const uint8Array = new Uint8Array(token.len);\n    const len = await this.peekBuffer(uint8Array, {\n      position\n    });\n    if (len < token.len) throw new EndOfStreamError();\n    return token.get(uint8Array, 0);\n  }\n  /**\r\n   * Read a numeric token from the stream\r\n   * @param token - Numeric token\r\n   * @returns Promise with number\r\n   */\n  async readNumber(token) {\n    const len = await this.readBuffer(this.numBuffer, {\n      length: token.len\n    });\n    if (len < token.len) throw new EndOfStreamError();\n    return token.get(this.numBuffer, 0);\n  }\n  /**\r\n   * Read a numeric token from the stream\r\n   * @param token - Numeric token\r\n   * @returns Promise with number\r\n   */\n  async peekNumber(token) {\n    const len = await this.peekBuffer(this.numBuffer, {\n      length: token.len\n    });\n    if (len < token.len) throw new EndOfStreamError();\n    return token.get(this.numBuffer, 0);\n  }\n  /**\r\n   * Ignore number of bytes, advances the pointer in under tokenizer-stream.\r\n   * @param length - Number of bytes to ignore\r\n   * @return resolves the number of bytes ignored, equals length if this available, otherwise the number of bytes available\r\n   */\n  async ignore(length) {\n    if (this.fileInfo.size !== undefined) {\n      const bytesLeft = this.fileInfo.size - this.position;\n      if (length > bytesLeft) {\n        this.position += bytesLeft;\n        return bytesLeft;\n      }\n    }\n    this.position += length;\n    return length;\n  }\n  async close() {\n    await this.abort();\n    await this.onClose?.();\n  }\n  normalizeOptions(uint8Array, options) {\n    if (!this.supportsRandomAccess() && options && options.position !== undefined && options.position < this.position) {\n      throw new Error('`options.position` must be equal or greater than `tokenizer.position`');\n    }\n    return {\n      ...{\n        mayBeLess: false,\n        offset: 0,\n        length: uint8Array.length,\n        position: this.position\n      },\n      ...options\n    };\n  }\n  abort() {\n    return Promise.resolve(); // Ignore abort signal\n  }\n}","map":{"version":3,"names":["EndOfStreamError","AbstractTokenizer","constructor","options","numBuffer","Uint8Array","position","onClose","abortSignal","addEventListener","abort","readToken","token","uint8Array","len","readBuffer","get","peekToken","peekBuffer","readNumber","length","peekNumber","ignore","fileInfo","size","undefined","bytesLeft","close","normalizeOptions","supportsRandomAccess","Error","mayBeLess","offset","Promise","resolve"],"sources":["C:/projects/My projects/Vue/osi/node_modules/strtok3/lib/AbstractTokenizer.js"],"sourcesContent":["import { EndOfStreamError } from './stream/index.js';\r\n/**\r\n * Core tokenizer\r\n */\r\nexport class AbstractTokenizer {\r\n    /**\r\n     * Constructor\r\n     * @param options Tokenizer options\r\n     * @protected\r\n     */\r\n    constructor(options) {\r\n        this.numBuffer = new Uint8Array(8);\r\n        /**\r\n         * Tokenizer-stream position\r\n         */\r\n        this.position = 0;\r\n        this.onClose = options?.onClose;\r\n        if (options?.abortSignal) {\r\n            options.abortSignal.addEventListener('abort', () => {\r\n                this.abort();\r\n            });\r\n        }\r\n    }\r\n    /**\r\n     * Read a token from the tokenizer-stream\r\n     * @param token - The token to read\r\n     * @param position - If provided, the desired position in the tokenizer-stream\r\n     * @returns Promise with token data\r\n     */\r\n    async readToken(token, position = this.position) {\r\n        const uint8Array = new Uint8Array(token.len);\r\n        const len = await this.readBuffer(uint8Array, { position });\r\n        if (len < token.len)\r\n            throw new EndOfStreamError();\r\n        return token.get(uint8Array, 0);\r\n    }\r\n    /**\r\n     * Peek a token from the tokenizer-stream.\r\n     * @param token - Token to peek from the tokenizer-stream.\r\n     * @param position - Offset where to begin reading within the file. If position is null, data will be read from the current file position.\r\n     * @returns Promise with token data\r\n     */\r\n    async peekToken(token, position = this.position) {\r\n        const uint8Array = new Uint8Array(token.len);\r\n        const len = await this.peekBuffer(uint8Array, { position });\r\n        if (len < token.len)\r\n            throw new EndOfStreamError();\r\n        return token.get(uint8Array, 0);\r\n    }\r\n    /**\r\n     * Read a numeric token from the stream\r\n     * @param token - Numeric token\r\n     * @returns Promise with number\r\n     */\r\n    async readNumber(token) {\r\n        const len = await this.readBuffer(this.numBuffer, { length: token.len });\r\n        if (len < token.len)\r\n            throw new EndOfStreamError();\r\n        return token.get(this.numBuffer, 0);\r\n    }\r\n    /**\r\n     * Read a numeric token from the stream\r\n     * @param token - Numeric token\r\n     * @returns Promise with number\r\n     */\r\n    async peekNumber(token) {\r\n        const len = await this.peekBuffer(this.numBuffer, { length: token.len });\r\n        if (len < token.len)\r\n            throw new EndOfStreamError();\r\n        return token.get(this.numBuffer, 0);\r\n    }\r\n    /**\r\n     * Ignore number of bytes, advances the pointer in under tokenizer-stream.\r\n     * @param length - Number of bytes to ignore\r\n     * @return resolves the number of bytes ignored, equals length if this available, otherwise the number of bytes available\r\n     */\r\n    async ignore(length) {\r\n        if (this.fileInfo.size !== undefined) {\r\n            const bytesLeft = this.fileInfo.size - this.position;\r\n            if (length > bytesLeft) {\r\n                this.position += bytesLeft;\r\n                return bytesLeft;\r\n            }\r\n        }\r\n        this.position += length;\r\n        return length;\r\n    }\r\n    async close() {\r\n        await this.abort();\r\n        await this.onClose?.();\r\n    }\r\n    normalizeOptions(uint8Array, options) {\r\n        if (!this.supportsRandomAccess() && options && options.position !== undefined && options.position < this.position) {\r\n            throw new Error('`options.position` must be equal or greater than `tokenizer.position`');\r\n        }\r\n        return {\r\n            ...{\r\n                mayBeLess: false,\r\n                offset: 0,\r\n                length: uint8Array.length,\r\n                position: this.position\r\n            }, ...options\r\n        };\r\n    }\r\n    abort() {\r\n        return Promise.resolve(); // Ignore abort signal\r\n    }\r\n}\r\n"],"mappings":";;;;;;;;AAAA,SAASA,gBAAgB,QAAQ,mBAAmB;AACpD;AACA;AACA;AACA,OAAO,MAAMC,iBAAiB,CAAC;EAC3B;AACJ;AACA;AACA;AACA;EACIC,WAAWA,CAACC,OAAO,EAAE;IACjB,IAAI,CAACC,SAAS,GAAG,IAAIC,UAAU,CAAC,CAAC,CAAC;IAClC;AACR;AACA;IACQ,IAAI,CAACC,QAAQ,GAAG,CAAC;IACjB,IAAI,CAACC,OAAO,GAAGJ,OAAO,EAAEI,OAAO;IAC/B,IAAIJ,OAAO,EAAEK,WAAW,EAAE;MACtBL,OAAO,CAACK,WAAW,CAACC,gBAAgB,CAAC,OAAO,EAAE,MAAM;QAChD,IAAI,CAACC,KAAK,CAAC,CAAC;MAChB,CAAC,CAAC;IACN;EACJ;EACA;AACJ;AACA;AACA;AACA;AACA;EACI,MAAMC,SAASA,CAACC,KAAK,EAAEN,QAAQ,GAAG,IAAI,CAACA,QAAQ,EAAE;IAC7C,MAAMO,UAAU,GAAG,IAAIR,UAAU,CAACO,KAAK,CAACE,GAAG,CAAC;IAC5C,MAAMA,GAAG,GAAG,MAAM,IAAI,CAACC,UAAU,CAACF,UAAU,EAAE;MAAEP;IAAS,CAAC,CAAC;IAC3D,IAAIQ,GAAG,GAAGF,KAAK,CAACE,GAAG,EACf,MAAM,IAAId,gBAAgB,CAAC,CAAC;IAChC,OAAOY,KAAK,CAACI,GAAG,CAACH,UAAU,EAAE,CAAC,CAAC;EACnC;EACA;AACJ;AACA;AACA;AACA;AACA;EACI,MAAMI,SAASA,CAACL,KAAK,EAAEN,QAAQ,GAAG,IAAI,CAACA,QAAQ,EAAE;IAC7C,MAAMO,UAAU,GAAG,IAAIR,UAAU,CAACO,KAAK,CAACE,GAAG,CAAC;IAC5C,MAAMA,GAAG,GAAG,MAAM,IAAI,CAACI,UAAU,CAACL,UAAU,EAAE;MAAEP;IAAS,CAAC,CAAC;IAC3D,IAAIQ,GAAG,GAAGF,KAAK,CAACE,GAAG,EACf,MAAM,IAAId,gBAAgB,CAAC,CAAC;IAChC,OAAOY,KAAK,CAACI,GAAG,CAACH,UAAU,EAAE,CAAC,CAAC;EACnC;EACA;AACJ;AACA;AACA;AACA;EACI,MAAMM,UAAUA,CAACP,KAAK,EAAE;IACpB,MAAME,GAAG,GAAG,MAAM,IAAI,CAACC,UAAU,CAAC,IAAI,CAACX,SAAS,EAAE;MAAEgB,MAAM,EAAER,KAAK,CAACE;IAAI,CAAC,CAAC;IACxE,IAAIA,GAAG,GAAGF,KAAK,CAACE,GAAG,EACf,MAAM,IAAId,gBAAgB,CAAC,CAAC;IAChC,OAAOY,KAAK,CAACI,GAAG,CAAC,IAAI,CAACZ,SAAS,EAAE,CAAC,CAAC;EACvC;EACA;AACJ;AACA;AACA;AACA;EACI,MAAMiB,UAAUA,CAACT,KAAK,EAAE;IACpB,MAAME,GAAG,GAAG,MAAM,IAAI,CAACI,UAAU,CAAC,IAAI,CAACd,SAAS,EAAE;MAAEgB,MAAM,EAAER,KAAK,CAACE;IAAI,CAAC,CAAC;IACxE,IAAIA,GAAG,GAAGF,KAAK,CAACE,GAAG,EACf,MAAM,IAAId,gBAAgB,CAAC,CAAC;IAChC,OAAOY,KAAK,CAACI,GAAG,CAAC,IAAI,CAACZ,SAAS,EAAE,CAAC,CAAC;EACvC;EACA;AACJ;AACA;AACA;AACA;EACI,MAAMkB,MAAMA,CAACF,MAAM,EAAE;IACjB,IAAI,IAAI,CAACG,QAAQ,CAACC,IAAI,KAAKC,SAAS,EAAE;MAClC,MAAMC,SAAS,GAAG,IAAI,CAACH,QAAQ,CAACC,IAAI,GAAG,IAAI,CAAClB,QAAQ;MACpD,IAAIc,MAAM,GAAGM,SAAS,EAAE;QACpB,IAAI,CAACpB,QAAQ,IAAIoB,SAAS;QAC1B,OAAOA,SAAS;MACpB;IACJ;IACA,IAAI,CAACpB,QAAQ,IAAIc,MAAM;IACvB,OAAOA,MAAM;EACjB;EACA,MAAMO,KAAKA,CAAA,EAAG;IACV,MAAM,IAAI,CAACjB,KAAK,CAAC,CAAC;IAClB,MAAM,IAAI,CAACH,OAAO,GAAG,CAAC;EAC1B;EACAqB,gBAAgBA,CAACf,UAAU,EAAEV,OAAO,EAAE;IAClC,IAAI,CAAC,IAAI,CAAC0B,oBAAoB,CAAC,CAAC,IAAI1B,OAAO,IAAIA,OAAO,CAACG,QAAQ,KAAKmB,SAAS,IAAItB,OAAO,CAACG,QAAQ,GAAG,IAAI,CAACA,QAAQ,EAAE;MAC/G,MAAM,IAAIwB,KAAK,CAAC,uEAAuE,CAAC;IAC5F;IACA,OAAO;MACH,GAAG;QACCC,SAAS,EAAE,KAAK;QAChBC,MAAM,EAAE,CAAC;QACTZ,MAAM,EAAEP,UAAU,CAACO,MAAM;QACzBd,QAAQ,EAAE,IAAI,CAACA;MACnB,CAAC;MAAE,GAAGH;IACV,CAAC;EACL;EACAO,KAAKA,CAAA,EAAG;IACJ,OAAOuB,OAAO,CAACC,OAAO,CAAC,CAAC,CAAC,CAAC;EAC9B;AACJ","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}